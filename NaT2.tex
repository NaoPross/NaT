\documentclass[a4paper, twocolumn]{article}

%
% Packages
%

%% styling for this document
\usepackage{tex/docstyle}

%
% Metadata
%

\title{Nachrichtentechnik 2}
\author{
  Naoki Pross
}
\date{\today}

%
% Macros
%

\newcommand{\overbar}[1]{\mkern 2mu\overline{\mkern-2mu#1\mkern-1mu}\mkern 1mu}

%
% Document
%

\begin{document}
\maketitle
% \tableofcontents

\section{Probability}
\begin{defn}[Random experiment]
  An experiment is called \emph{random} if its outcome cannot be predicted.
\end{defn}

\begin{defn}[Sample space and events]
  The set of all possible outcomes of a random experiment is called the
  \emph{sample space} \(S\). An \(\lambda \in S\) is called a \emph{sample
  point}. A set of sample points \(A \subseteq S\) is called an \emph{event}.
  The set with no sample points \(\emptyset\) is the \emph{impossible event}.
\end{defn}

\begin{defn}[Complement] The complement of an event \(A\) is
  \(\overbar{A} = \{\lambda \in S :  \lambda \notin A\}\).
  That is, the event when \(A\) does not happen.
\end{defn}

\begin{defn}[Union and intersection]
  Given two events \(A, B \subseteq S\) their \emph{union} and \emph{intersection}
  are respectively:
  \begin{itemize}
    \item \(A\cup B = \{\lambda \in S : (\lambda \in A) \vee (\lambda \in B)\}\)
    \item \(A\cap B = \{\lambda \in S : (\lambda \in A) \wedge (\lambda \in B)\}\)
  \end{itemize}
  If \(A\cap B = \emptyset\) then \(A\) and \(B\) are said to be \emph{disjoint}.
  Both \(\cup\) and \(\cap\) are associative, commutative and distributive on
  each other:
  \begin{itemize}
    \item \(A\cup (B\cap C) = (A\cup B) \cap (A\cup C)\)
    \item \(A\cap (B\cup C) = (A\cap B) \cup (A\cap C)\)
  \end{itemize}
\end{defn}

\begin{theorem}[DeMorgan's Law]
  Let \(A, B \subseteq S\)
  \begin{equation}
    \overbar{A\cup B} = \overbar{A}\cap \overbar{B} 
    \quad\text{and}\quad
    \overbar{A\cap B} = \overbar{A}\cup \overbar{B}
  \end{equation}
\end{theorem}

\begin{defn}[Probability]
  We assign a real number between 0 and 1 called \emph{probability} to each
  event in \(S\).  The following 3 axioms are enough to define it.
  \begin{enumerate}
    \item \(P(A) \geq 0\),
    \item \(P(S) = 1\),
    \item \(P(A\cup B) = P(A) + P(B)\) if \(A\cap B = \emptyset\).
  \end{enumerate}
\end{defn}

\begin{lemma}[Useful laws of probability]
  Although the axiomatic definition is complete, it is not very useful on its own.
  Here are some other expressions that can be derived from the axioms:
  \begin{enumerate}
    \item \(P(A) \leq 1\)
    \item \(P(\overbar{A}) = 1 - P(A)\)
    \item \(P(\emptyset) = 0\)
    \item \(P(A) \leq P(B)\) if \(A\subseteq B\)
    \item \(P(A\cup B) = P(A) + P(B) - P(A\cap B)\)
  \end{enumerate}
\end{lemma}

\begin{remark}
  In the case where \(S\) has a finite number of events, the probability can be
  thought of as a function \(P: \mathcal{P}(S) \to [0,1]\) from the power set
  of \(S\) to the interval between 0 and 1. 
\end{remark}

\section{Random Variables}

\begin{defn}[Random Variable]
  For a random experiment with sample space \(S\), we assign to each sample point \(\lambda\)
\end{defn}

\section{Random Processes}

Previously we defined a random variable as a function \(X: S \to
E\subset\mathbb{R}\) that assigns a \emph{number} to each event. We will now
extend this concept.

\begin{defn}[Random Process]
  For a random experiment with sample space \(S\), we assign to every sample
  point \(\lambda \in S\) a \emph{function} of time. The \emph{random process}
  \(X(t, \lambda)\) is effectively \(X : \mathbb{R} \times S \to E
  \subseteq\mathbb{R}\).
\end{defn}

\begin{remark}
  Notice that for a fixed \(\lambda_i\), \(X(t,\lambda_i) = x_i(t)\) is indeed a
  function of time. Whereas for a fixed time \(t_j\) is \(X(t_j, \lambda) = X_j\),
  a random variable. Only when both a \(\lambda_i\) and \(t_j\) are given
  \(X(t_j, \lambda_i)\) is a number.
\end{remark}

\begin{defn}[Probability distribution and density function]
  A random process \(X(t, \lambda)\) at a particular time \(t\) \emph{is} a
  random variable with distribution
  \begin{align}
    F_X(t, x) &= P(X \leq x) \\
      &= P(\{\lambda\in S : X(t, \lambda) \leq x\})
  \end{align}
  and a corresponding density function
  \begin{equation}
    f_X(t, x) = \frac{\partial F_X(t, x)}{\partial x}
\end{equation}
\end{defn}

\begin{remark}
\end{remark}

\end{document}
